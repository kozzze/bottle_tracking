import cv2
import numpy as np
from ultralytics import YOLO

# ğŸ¨ Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: grayscale + alpha/beta + ĞºĞ¾Ğ½Ñ‚ÑƒÑ€Ñ‹
def full_enhance(img):
    img = cv2.convertScaleAbs(img, alpha=1.2, beta=1)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    edges = cv2.Canny(gray, 100, 200)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contour_mask = np.zeros_like(gray_bgr)
    cv2.drawContours(contour_mask, contours, -1, (255,255,255), 1)
    return cv2.addWeighted(gray_bgr, 0.8, contour_mask, 0.2, 0)

# ğŸ“ IoU Ğ¸ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
def iou(boxA, boxB):
    xa, ya, xa2, ya2 = boxA
    xb, yb, xb2, yb2 = boxB
    inter_x1, inter_y1 = max(xa, xb), max(ya, yb)
    inter_x2, inter_y2 = min(xa2, xb2), min(ya2, yb2)
    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
    areaA = max(1, (xa2 - xa) * (ya2 - ya))
    areaB = max(1, (xb2 - xb) * (yb2 - yb))
    union = areaA + areaB - inter_area
    return inter_area / union if union > 0 else 0

def center_distance(boxA, boxB):
    ax = (boxA[0] + boxA[2]) / 2
    ay = (boxA[1] + boxA[3]) / 2
    bx = (boxB[0] + boxB[2]) / 2
    by = (boxB[1] + boxB[3]) / 2
    return ((ax - bx)**2 + (ay - by)**2)**0.5

# ğŸ“Š ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğ¹
def analyze(img, gt_boxes, model, conf_thresh, iou_thresh, dist_thresh):
    annotated = img.copy()
    results = model.predict(img, conf=conf_thresh, verbose=False)[0]
    preds = [list(map(int, box.xyxy[0])) for box in results.boxes if float(box.conf[0]) >= conf_thresh]

    matched_gt, matched_pred = set(), set()
    tp, fp = 0, 0
    ious, dists = [], []

    for i, pred in enumerate(preds):
        best_iou, best_gt = 0, None
        for j, gt in enumerate(gt_boxes):
            if j in matched_gt:
                continue
            iou_score = iou(pred, gt)
            dist = center_distance(pred, gt)
            if iou_score >= iou_thresh and dist <= dist_thresh and iou_score > best_iou:
                best_iou, best_gt = iou_score, j
        if best_gt is not None:
            matched_gt.add(best_gt)
            matched_pred.add(i)
            tp += 1
            ious.append(best_iou)
            dists.append(center_distance(pred, gt_boxes[best_gt]))
            cv2.rectangle(annotated, (pred[0], pred[1]), (pred[2], pred[3]), (0,255,0), 2)
        else:
            fp += 1
            cv2.rectangle(annotated, (pred[0], pred[1]), (pred[2], pred[3]), (255,0,255), 2)
    fn = len(gt_boxes) - tp
    for gt in gt_boxes:
        cv2.rectangle(annotated, (gt[0], gt[1]), (gt[2], gt[3]), (0,0,255), 2)

    precision = tp / (tp + fp) if tp + fp > 0 else 0
    recall = tp / (tp + fn) if tp + fn > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0
    mean_iou = sum(ious)/len(ious) if ious else 0
    mean_dist = sum(dists)/len(dists) if dists else 0
    map_at_iou = tp / len(preds) if preds else 0

    return annotated, {
        'tp': tp, 'fp': fp, 'fn': fn,
        'precision': precision, 'recall': recall, 'f1': f1,
        'mean_iou': mean_iou,
        'mean_dist': mean_dist,
        'map': map_at_iou,
        'gt_count': len(gt_boxes),
        'pred_count': len(preds)
    }

# ğŸ”§ ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
image_path = '/Users/kozzze/Desktop/Ğ£Ñ‡ĞµĞ±Ğ°/bottle_tracking/work/barier/images/test/74.jpg'
label_path = '/Users/kozzze/Desktop/Ğ£Ñ‡ĞµĞ±Ğ°/bottle_tracking/work/barier/labels/test/74.txt'
model_path = '/Users/kozzze/Desktop/Ğ£Ñ‡ĞµĞ±Ğ°/bottle_tracking/work/barier/runs/detect/train/weights/best.pt'
conf_thresh = 0.3
iou_thresh = 0.3
distance_thresh = 50
model = YOLO(model_path)

# ğŸ“¥ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ GT
img = cv2.imread(image_path)
h, w = img.shape[:2]
gt_boxes = []
with open(label_path, 'r') as f:
    for line in f:
        cls, cx, cy, bw, bh = map(float, line.strip().split())
        x1 = int((cx - bw / 2) * w)
        y1 = int((cy - bh / 2) * h)
        x2 = int((cx + bw / 2) * w)
        y2 = int((cy + bh / 2) * h)
        gt_boxes.append([x1, y1, x2, y2])

# ğŸ§ª ĞĞ½Ğ°Ğ»Ğ¸Ğ·: Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ» Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğµ
img_enhanced = full_enhance(img.copy())
res1_img, res1_metrics = analyze(img, gt_boxes, model, conf_thresh, iou_thresh, distance_thresh)
res2_img, res2_metrics = analyze(img_enhanced, gt_boxes, model, conf_thresh, iou_thresh, distance_thresh)

# ğŸ“‹ Ğ’Ñ‹Ğ²Ğ¾Ğ´ Ğ² ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ
def print_metrics(name, res):
    print(f"\nğŸ“Š {name}")
    print(f"GT-Ğ±Ğ¾ĞºÑĞ¾Ğ²: {res['gt_count']} | ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¾: {res['pred_count']}")
    print(f"âœ… TP: {res['tp']} | âŒ FP: {res['fp']} | âš ï¸ FN: {res['fn']}")
    print(f"ğŸ“ Ğ¡Ñ€. IoU:       {res['mean_iou']:.3f}")
    print(f"ğŸ“ Ğ¡Ñ€. Ñ€Ğ°ÑÑÑ‚. Ñ†.: {res['mean_dist']:.2f}px")
    print(f"ğŸ¯ Precision:     {res['precision']:.3f}")
    print(f"ğŸ“ˆ Recall:        {res['recall']:.3f}")
    print(f"ğŸ” F1-score:      {res['f1']:.3f}")
    print(f"ğŸ“¦ mAP@IoU:       {res['map']:.3f}")

print_metrics("Ğ¡Ğ¢ĞĞšĞĞ’ĞĞ•", res1_metrics)
print_metrics("Ğ˜Ğ—ĞœĞ•ĞĞĞĞĞĞ• (GREY + Î±Î² + ĞšĞ¾Ğ½Ñ‚ÑƒÑ€Ñ‹)", res2_metrics)

# ğŸ–¼ï¸ ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ñ‘Ğ½Ğ½Ğ¾Ğµ Ğ¾ĞºĞ½Ğ¾
def resize(img, scale=0.4):
    return cv2.resize(img, (0, 0), fx=scale, fy=scale)

combined = cv2.hconcat([resize(res1_img), resize(res2_img)])
cv2.imshow("Left: Stock | Right: Enhanced", combined)
cv2.waitKey(0)
cv2.destroyAllWindows()
